# LLM4AD

### 综述

- (2024.01.16) Forging Vision Foundation Models for Autonomous Driving: Challenges, Methodologies, and Opportunities
- (2024.06.20) Vision Language Models in Autonomous Driving: A Survey and Outlook
- (2024.10.20) Large Language Models for Autonomous Driving (LLM4AD): Concept, Benchmark, Simulation, and Real-Vehicle Experiment
- A Survey on Multimodal Large Language Models for Autonomous Driving

### VQA

- (2023.12.25) DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving
- (2024.03.20) LingoQA: Video Question Answering for Autonomous Driving
- (2024.06.25) DRIVEVLM: The Convergence of Autonomous Driving and Large Vision-Language Models
- (2024.07.17) DriveLM: Driving with Graph Visual Question Answering
- (2024.08.19) CoVLA: Comprehensive Vision-Language-Action Dataset for Autonomous Driving
- (2024.08.25) Making Large Language Models Better Planners with Reasoning-Decision Alignment
- (2024.10.07) HE-DRIVE: HUMAN-LIKE END-TO-END DRIVING WITH VISION LANGUAGE MODELS
- (2024.10.29) Senna: Bridging Large Vision-Language Models and End-to-End Autonomous Driving
- (2024.11.04) EMMA: End-to-End Multimodal Model for Autonomous Driving
- (2024.11.09) DriveGPT4: Interpretable End-to-end Autonomous Driving via Large Language Model
- (2024.11.20) Hints of Prompt: Enhancing Visual Representation for Multimodal LLMs in Autonomous Driving
- (2024.11.23) VLP: Vision Language Planning for Autonomous Driving

### 数据集

- NuPrompt
- (2024.02.20) NuScenes-QA: A Multi-Modal Visual Question Answering Benchmark for Autonomous Driving Scenario
- Rank2Tell
- BDD-X
- DRAMA
- DriveLM
- (2024.08.08) GenAD:Generalized Predictive Model for Autonomous Driving

### 世界模型

- DriveDreamer
- GAIA-1


### 研究机构

- wayve: https://wayve.ai/thinking/